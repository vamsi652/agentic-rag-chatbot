# ğŸ¤– Agentic RAG Chatbot using Model Context Protocol (MCP)

A multi-agent Retrieval-Augmented Generation (RAG) chatbot that allows users to upload various document formats (PDF, DOCX, PPTX, TXT, Markdown, CSV) and ask questions based on their content. It features a modular architecture using four intelligent agentsâ€”`IngestionAgent`, `RetrievalAgent`, `LLMResponseAgent`, and `CoordinatorAgent`â€”communicating through a structured Model Context Protocol (MCP).



![alt text](<Screenshot (127).png>)

---

## âœ… Features

- ğŸ“„ Upload and parse multiple document formats: `PDF`, `DOCX`, `PPTX`, `CSV`, `TXT`, `MD`
- ğŸ¤– Modular Agentic Design using:
  - **IngestionAgent** â€“ parses and preprocesses uploaded documents
  - **RetrievalAgent** â€“ generates embeddings and retrieves top-k context chunks
  - **LLMResponseAgent** â€“ builds LLM queries and generates final responses
  - **CoordinatorAgent** â€“ orchestrates the flow among other agents
- ğŸ”Œ Uses **Model Context Protocol (MCP)** for structured message passing
- ğŸ§  Embeddings via HuggingFace SentenceTransformers (`all-MiniLM-L6-v2`)
- ğŸ—ƒï¸ Vector storage with **FAISS**
- ğŸ—¨ï¸ LLM responses from **Together.ai** (`Mixtral` or `Mistral`)
- ğŸ’¬ Streamlit UI for file uploads, multi-turn question answering, and source-based answers

---

## ğŸ“ Folder Structure

```
agentic-rag-chatbot/
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ ingestion_agent.py
â”‚   â”œâ”€â”€ retrieval_agent.py
â”‚   â”œâ”€â”€ llm_response_agent.py
â”‚   â””â”€â”€ coordinator_agent.py
â”‚
â”œâ”€â”€ mcp/
â”‚   â””â”€â”€ protocol.py  # MCP message format
â”‚
â”œâ”€â”€ vector_store/
â”‚   â””â”€â”€ store.py
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py  # Streamlit app
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ uploaded_files/
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ file_parsers.py
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ demo_ppt.pptx
```

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/agentic-rag-chatbot.git
cd agentic-rag-chatbot
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Add API Key for Together.ai

You can export it via terminal:

```bash
export TOGETHER_API_KEY="tgp_v1_XXXXXXXXXXXX"
```

Or create a `.env` file in the project root:

```ini
TOGETHER_API_KEY=tgp_v1_XXXXXXXXXXXX
```

### 4. Run the Streamlit UI

```bash
streamlit run ui/app.py
```

The UI will launch at [http://localhost:8501](http://localhost:8501).

---

## ğŸ’¡ How It Works (Agentic Architecture)

### ğŸ§  Message Flow (Using MCP)

Each agent communicates using MCP messages structured like this:

```json
{
  "sender": "RetrievalAgent",
  "receiver": "LLMResponseAgent",
  "type": "CONTEXT_RESPONSE",
  "trace_id": "abc-123",
  "payload": {
    "top_chunks": ["doc1: KPIs include revenue", "slide3: growth by 12%"],
    "query": "What KPIs were tracked?"
  }
}
```

### âš™ï¸ Sample Workflow

User uploads: `sales_review.pdf`, `metrics.csv`

User asks: _"What KPIs were tracked in Q1?"_

Internally:

- `IngestionAgent` parses all documents and chunks content
- `RetrievalAgent` embeds chunks and retrieves top-k relevant ones
- `LLMResponseAgent` builds a prompt using retrieved chunks and queries the Together.ai LLM
- `CoordinatorAgent` coordinates flow among agents
- Response is shown in the UI with source references

---

## ğŸ§  Technologies Used

| Component           | Technology                      |
|--------------------|----------------------------------|
| Language Model      | Together.ai (Mixtral, Mistral)  |
| Embeddings          | SentenceTransformers (MiniLM)   |
| Vector DB           | FAISS                           |
| Frontend            | Streamlit                       |
| Document Parsing    | PyMuPDF, python-docx, pptx, pandas |
| Message Protocol    | Custom in-memory MCP            |

---

## ğŸ“¦ Requirements

```
streamlit
python-dotenv
sentence-transformers
faiss-cpu
PyMuPDF
python-docx
python-pptx
pandas
together
```

Install with:

```bash
pip install -r requirements.txt
```

---

## ğŸ“Œ Challenges Faced

- Handling inconsistent document encoding and structure across formats
- Ensuring all agents consistently follow the MCP message schema
- Optimizing context chunking for large documents
- Integrating Together.ai within limited token budget

---


## ğŸ“„ License

MIT License. Feel free to use and modify with credit.

---

## ğŸ“¬ Contact

For queries or feedback, open an issue or contact **Your Name**.
